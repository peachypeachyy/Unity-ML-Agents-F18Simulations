Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-0.15957485,999.0,33.92953237689411,33.92953237689411,1.0
20000,1.4189383,-0.15179951,999.0,-1.0876201609149576,-1.0876201609149576,1.0
30000,1.4189826,0.023982119,999.0,132.46369297914208,132.46369297914208,1.0
40000,1.4189854,-0.09285309,999.0,1467.978426756384,1467.978426756384,1.0
50000,1.4188192,0.16103229,999.0,153.43278921928723,153.43278921928723,1.0
60000,1.4187998,-0.07537785,999.0,9.25895974203595,9.25895974203595,1.0
70000,1.4187567,0.17499575,999.0,38.02067932507489,38.02067932507489,1.0
80000,1.4187489,0.06050387,999.0,-0.6803900580620393,-0.6803900580620393,1.0
90000,1.4187961,0.042797774,999.0,14.767748217307963,14.767748217307963,1.0
100000,1.4188082,0.14279759,999.0,7.49235001662746,7.49235001662746,1.0
