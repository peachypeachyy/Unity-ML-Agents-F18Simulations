Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,0.19733426,999.0,35.31109344959259,35.31109344959259,1.0
20000,1.4189383,0.24497509,999.0,35.66650583744049,35.66650583744049,1.0
30000,1.4162978,0.5666232,999.0,33.59642961025238,33.59642961025238,1.0
40000,1.4161499,0.59341085,999.0,36.49738005399704,36.49738005399704,1.0
50000,1.4159052,0.9675783,999.0,36.14540526866913,36.14540526866913,1.0
60000,1.4158783,0.949842,999.0,35.84660360813141,35.84660360813141,1.0
70000,1.4146392,1.2240714,999.0,35.889532279968265,35.889532279968265,1.0
80000,1.4144135,1.2282926,999.0,34.80296903848648,34.80296903848648,1.0
90000,1.4139699,1.5220768,999.0,35.67737085819245,35.67737085819245,1.0
100000,1.4138587,1.5410831,999.0,34.00560550689697,34.00560550689697,1.0
110000,1.4143542,1.7978745,999.0,36.1395679473877,36.1395679473877,1.0
120000,1.414522,1.854661,999.0,36.164404201507566,36.164404201507566,1.0
130000,1.4140112,1.944857,999.0,35.229855477809906,35.229855477809906,1.0
140000,1.4137897,2.100331,999.0,36.41622116565704,36.41622116565704,1.0
150000,1.4128733,2.143662,999.0,34.89471584558487,34.89471584558487,1.0
160000,1.4123732,2.2771761,999.0,35.203377795219424,35.203377795219424,1.0
170000,1.4122845,2.4265907,999.0,36.147243404388426,36.147243404388426,1.0
180000,1.4122256,2.464642,999.0,36.252642726898195,36.252642726898195,1.0
190000,1.4119015,2.56416,999.0,36.79710419178009,36.79710419178009,1.0
