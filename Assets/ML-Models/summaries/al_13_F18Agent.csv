Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,0.11531789,999.0,935.7969959709379,935.7969959709379,1.0
20000,1.4189383,0.30356508,999.0,1001.2973425388336,1001.2973425388336,1.0
30000,1.4197105,0.043341734,999.0,398.9907198190689,398.9907198190689,1.0
40000,1.419754,0.24768071,999.0,1515.5722877025605,1515.5722877025605,1.0
50000,1.4204258,0.37564677,999.0,1028.3859002113343,1028.3859002113343,1.0
60000,1.4205055,0.23214479,999.0,1442.2918941497803,1442.2918941497803,1.0
70000,1.4200298,0.50441515,999.0,1354.98503510952,1354.98503510952,1.0
80000,1.4199396,0.64120716,999.0,-28.350233030319213,-28.350233030319213,1.0
90000,1.4178537,0.68253213,999.0,-28.36155958175659,-28.36155958175659,1.0
100000,1.4173124,0.6361402,999.0,-28.447093105316164,-28.447093105316164,1.0
110000,1.4171226,0.6384118,999.0,-28.348747205734252,-28.348747205734252,1.0
