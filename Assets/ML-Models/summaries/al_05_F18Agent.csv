Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,4.255976,999.0,2562.669908311632,2562.669908311632,1.0
20000,1.4189383,4.9614196,999.0,2626.0165779113768,2626.0165779113768,1.0
30000,1.4186225,11.3911495,999.0,2669.7447456359864,2669.7447456359864,1.0
40000,1.4186057,10.880416,999.0,2657.9415283203125,2657.9415283203125,1.0
50000,1.420397,14.7962265,999.0,2574.3316383361816,2574.3316383361816,1.0
60000,1.4206034,15.65744,999.0,2521.5132698059083,2521.5132698059083,1.0
70000,1.4216526,17.321764,999.0,2592.5108963012694,2592.5108963012694,1.0
80000,1.4218423,19.335316,999.0,2761.0005424499514,2761.0005424499514,1.0
90000,1.4208711,19.25035,999.0,2528.8839893341064,2528.8839893341064,1.0
100000,1.4206244,22.711601,999.0,2572.2677169799804,2572.2677169799804,1.0
110000,1.4225107,21.24557,999.0,2585.3722908020018,2585.3722908020018,1.0
